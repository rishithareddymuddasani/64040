---
title: "Assignment 3"
author: "Rishitha Reddy Muddasani"
date: "2023-03-04"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r Call csv and factor variables}
library(caret)
library(dplyr)
library(ggplot2)
library(lattice)
library(knitr)
library(rmarkdown)
library(e1071)
```

```{r}
RR <- read.csv("~/Documents/assignments/FUNDAMENTALS ML/UniversalBank.csv")
```

```{r}
##The following portion simply extracts the csv file, eliminates ID and zip code (like last time, but pointlessly), and then makes the suitable variables factors,change numerical variables to categorical first.
RR1<- RR %>% select(Age, Experience, Income, Family, CCAvg, Education, Mortgage, Personal.Loan, Securities.Account, CD.Account, Online, CreditCard)
RR1$CreditCard <- as.factor(RR1$CreditCard)
RR1$Personal.Loan <- as.factor((RR1$Personal.Loan))
RR1$Online <- as.factor(RR1$Online)
```

```{r}
#This creates the data partition, train data and validation data
selected.var <- c(8,11,12)
set.seed(23)
Train_Index = createDataPartition(RR1$Personal.Loan, p=0.60, list=FALSE)
Train_Data = RR1[Train_Index,selected.var]
Validation_Data = RR1[-Train_Index,selected.var]
```

```{r A}
##A. Create a pivot table for the training data with Online as a column variable, CC as a row variable,and Loan as a secondary row variable. The values inside the table should convey the count. In R use functions melt() and cast(), or function table(). In Python, use panda dataframe methods melt() and pivot().
#CC and LOAN are both rows and online is a column in the generated pivot table.
attach(Train_Data)
##ftable "function table". 
ftable(CreditCard,Personal.Loan,Online)
detach(Train_Data)
```

##Given that Online=1 and CC=1, we add 53 (Loan=1 from ftable) to 497 (Loan=0 from ftable), which equals 550, to obtain the conditional probability that Loan=1. 53/550 = 0.096363 or 9.64% of the time.

```{r}
##B. Consider the task of classifying a customer who owns a bank credit card and is actively using online banking services. Looking at the pivot table, what is the probability that this customer will accept the loan offer? [This is the probability of loan acceptance (Loan = 1) conditional on having a bank credit card (CC = 1) and being an active user of online banking services (Online = 1)].
prop.table(ftable(Train_Data$CreditCard,Train_Data$Online,Train_Data$Personal.Loan),margin=1)
```

##The code above displays a percentage pivot table, which shows the probabilities of a loan based on CC and online.

```{r}
##C. Create two separate pivot tables for the training data. One will have Loan (rows) as a function of Online (columns) and the other will have Loan (rows) as a function of CC.
attach(Train_Data)
ftable(Personal.Loan,Online)
ftable(Personal.Loan,CreditCard)
detach(Train_Data)
```

##Above in the first, "Online" compensates a column, "Loans" puts up a row, and "Credit Card" compensates a column.

```{r}
##D. Compute the following quantities [P(A | B) means “the probability ofA given B”]:  
prop.table(ftable(Train_Data$Personal.Loan,Train_Data$CreditCard),margin=)
prop.table(ftable(Train_Data$Personal.Loan,Train_Data$Online),margin=1)
```

RRi) 92/288 = 0.3194 or 31.94%

RRii) 167/288 = 0.5798 or 57.986%

RRiii) total loans= 1 from table (288) divide by total from table (3000) = 0.096 or 9.6%

RRiV) 812/2712 = 0.2994 or 29.94%

RRV) 1624/2712 = 0.5988 or 59.88%

RRVi) total loans=0 from table(2712) divided by total from table (3000) = 0.904 or 90.4%

##E. Use the quantities computed above to compute the naive Bayes probability P(Loan = 1 | CC = 1,Online = 1).

(0.3194 * 0.5798 * 0.096)/[(0.3194 * 0.5798 * 0.096)+(0.2994 * 0.5988 * 0.904)] = 0.0988505642823701 or 9.885%

##F. Compare this value with the one obtained from the pivot table in (B). Which is a more accurate estimate? 

There is no significant difference between 0.096363, or 9.64%, and 0.0988505642823701, or 9.885%. The pivot table value is the more accurate estimated value since it does not rely on the probabilities being independent. Whereas E examines the probability of each of those counts, B uses a direct computation from a count. As a result, B is more specific, whereas E is more generic.

```{r}
##G. Which of the entries in this table are needed for computing P(Loan = 1 | CC = 1, Online = 1)? Run naive Bayes on the data. Examine the model output on training data, and find the entry that corresponds to P(Loan = 1 | CC = 1, Online = 1). Compare this to the number you obtained in (E). 
##TRAINING dataset
RR.nb <- naiveBayes(Personal.Loan ~ ., data = Train_Data)
RR.nb
```
The pivot table in step B may be used to quickly compute P(LOAN=1|CC=1,Online=1) without using the Naive Bayes model, whereas using the two tables produced in step C makes it simple and obvious HOW you are computing P(LOAN=1|CC=1,Online=1) by using Naive Bayes model.

However,the model forecast is lower than the probability estimated manually in step E. The Naive Bayes model predicts the same probability as the preceding techniques. The predicted probability is closer to the one from step B. This is possible because step E needs manual computation, which raises the chance of error when rounding fractions and resulting in a rough estimate.

```{r}
## NB confusion matrix for Train_Data
##TRAINING
pred.class <- predict(RR.nb, newdata = Train_Data)
confusionMatrix(pred.class, Train_Data$Personal.Loan)
```

Despite being highly sensitive, this model had a low specificity. The model projected that all values would be 0 in the absence of all real values from the reference. Because of the enormous number of 0, even if the model missed all values of 1, it still yields 90.4% accuracy.

```{r Validation set}
pred.prob <- predict(RR.nb, newdata=Validation_Data, type="raw")
pred.class <- predict(RR.nb, newdata = Validation_Data)
confusionMatrix(pred.class, Validation_Data$Personal.Loan)
```

Let's look at the model graphically and choose the ideal threshold.

```{r ROC}
library(pROC)
roc(Validation_Data$Personal.Loan,pred.prob[,1])
plot.roc(Validation_Data$Personal.Loan,pred.prob[,1],print.thres="best")
```

As a response, it can be established that using a cutoff of 0.906 might enhance the model by lowering sensitivity to 0.495 and increasing specificity to 0.576.
